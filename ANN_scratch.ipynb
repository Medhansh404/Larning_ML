{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9057995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shoutout to the YT channel @samson for the inspiration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0ae46",
   "metadata": {},
   "source": [
    "# Today i'll be implementing ANN in python from scratch without using tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8241603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets's begin \n",
    "# Maths behind the ANN \n",
    "# We make input np arrays as we can't perform \"Maths\" on df duhhhh and pandas not allowed :)\n",
    "# We also convert the data to be fed to any different layers \n",
    "# 1). This layer will be the input layer there will be 784 (28*28) values as input\n",
    "# random weights and biases(-0.5, 0.5) will be appointed to the hidden layer 1 output\n",
    "# 2). This is the hidden layer 1 where we are using activation function ReLU and we propogate to the nes=ext layer\n",
    "# again during propagation we add some weights and biases moving ahead\n",
    "# 3). This is the hidden layer 2 where we get result from hidden layer 1 and we have decided to apply softmax on this layer\n",
    "# We get the answer from the maximum of all the softmax values.\n",
    "# This is not it though the beauty of neural networks lie in thier upadation tendencies that is where the \"Learning\" part comes in\n",
    "# Here we will propagate back to update the weights in the earlier layers as per the deviation of the predicted value with the real value.\n",
    "# and we will this till we achieve a grasp of the data\n",
    "# Similar logic to regression thing.\n",
    "# ANN is just a glorified and multidimensional regression without the activation functions(What i think)\n",
    "# At last we can apply some analysing measures to see our results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c291bf8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Loading the MNIST digit recognition dataset for this model\n",
    "data = pd.read_csv(\"./MNIST.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "341e9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok no cheating \n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "\n",
    "np.random.shuffle(data) # shuffling before splitting into test and training sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d708f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[0:1000].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n]\n",
    "X_test = X_test / 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99c7e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c5c189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 7, ..., 5, 4, 9], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70486d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we start the maths part\n",
    "# Before anything we should define the activation functions and their derivativefor our ease \n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "def softmax(z):\n",
    "    A = np.exp(z)/sum(np.exp(z))\n",
    "    return A\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddec464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function for getting y in the proper format when we have to compare it with the output of our fwd prop function\n",
    "def modified_Y(Y):\n",
    "    modf_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    modf_Y[np.arange(Y.size), Y] = 1\n",
    "    modf_Y = modf_Y.T\n",
    "    return modf_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2b52f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising random variables for weights in layers\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10,1) -0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10,1) -0.5\n",
    "    return W1, b1, W2, b2\n",
    "# Now we forward propogate with the weightds and biaes in our hand\n",
    "def fwd_prop(W1, W2, b1, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "# Now we back propogate\n",
    "def back_prop(W1, W2, A1, A2, Z1, Z2, X, Y):\n",
    "    modf_Y = modified_Y(Y)\n",
    "    dZ2 = A2 - modf_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "# Upgrading the weights from what we leared\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d1097ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysising our model through accuracy and visualisisng\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "# Runs the process of fwd and bckwd prop miultiple times to refine our model \n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = fwd_prop(W1, W2, b1, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(W1, W2, A1, A2, Z1, Z2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 50 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aeba907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[2 4 4 ... 2 6 2] [6 9 7 ... 5 4 9]\n",
      "0.12797560975609756\n",
      "Iteration:  50\n",
      "[0 4 9 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.4961219512195122\n",
      "Iteration:  100\n",
      "[0 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.6340975609756098\n",
      "Iteration:  150\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.702780487804878\n",
      "Iteration:  200\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.7438292682926829\n",
      "Iteration:  250\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.7706585365853659\n",
      "Iteration:  300\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.7893414634146342\n",
      "Iteration:  350\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.8033658536585366\n",
      "Iteration:  400\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.8156097560975609\n",
      "Iteration:  450\n",
      "[6 9 7 ... 3 4 9] [6 9 7 ... 5 4 9]\n",
      "0.8246829268292682\n"
     ]
    }
   ],
   "source": [
    "# Testing with learning rate of 0.10\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f8218ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = fwd_prop(W1, W2, b1, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "342bf733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 7 9 7 7 4 3 8 9 0 8 4 6 2 1 2 8 8 1 2 0 8 7 7 6 6 3 0 8 5 6 2 1 9 3 5\n",
      " 2 9 7 4 2 5 3 5 0 2 3 6 7 9 4 3 4 1 1 1 8 8 1 4 4 2 1 8 0 4 9 3 4 4 3 6 6\n",
      " 0 3 6 8 2 9 7 6 1 5 4 1 7 5 6 3 8 1 8 6 5 8 3 9 1 4 8 3 5 1 0 9 0 0 7 5 6\n",
      " 9 5 7 2 1 9 7 3 1 2 6 9 2 9 5 6 4 2 7 9 2 3 1 2 2 8 3 9 8 8 1 0 7 3 5 3 9\n",
      " 7 2 8 2 5 6 3 9 1 7 8 8 0 5 0 9 0 6 0 7 3 8 9 6 3 6 7 6 0 1 5 3 5 3 2 6 3\n",
      " 7 6 3 6 1 1 6 8 1 2 0 0 3 6 5 3 2 7 1 6 6 6 1 5 5 9 4 0 1 0 0 8 3 6 3 5 0\n",
      " 3 8 7 0 7 6 0 9 9 9 4 2 5 7 2 6 3 8 1 7 1 4 1 3 6 1 8 9 1 7 4 7 8 2 2 9 2\n",
      " 7 7 8 5 5 2 4 1 7 0 2 1 0 4 2 9 2 8 1 1 9 0 1 4 5 3 8 1 4 4 8 0 9 2 3 0 0\n",
      " 1 7 3 7 6 8 2 8 0 9 1 0 6 3 2 4 8 2 8 7 9 1 5 7 2 6 8 1 0 3 2 1 1 2 7 7 9\n",
      " 6 4 1 9 4 0 4 9 6 7 4 0 0 7 6 9 5 1 9 8 5 4 2 8 6 0 4 9 7 9 5 1 0 1 0 3 1\n",
      " 6 8 9 8 6 2 7 5 7 3 5 5 3 0 2 7 5 9 1 6 0 3 9 1 6 4 8 5 5 7 1 6 2 7 3 6 9\n",
      " 2 7 3 6 1 2 6 1 5 7 9 3 2 8 9 6 2 2 8 5 0 6 6 4 9 4 6 0 8 6 1 1 5 6 0 1 6\n",
      " 9 1 1 9 7 0 8 7 8 1 6 4 1 1 5 4 4 6 9 9 0 4 6 0 8 0 0 5 8 3 4 4 5 4 6 3 8\n",
      " 1 6 5 9 4 2 9 8 9 4 5 1 7 6 7 7 3 0 1 1 4 4 8 0 6 9 4 2 2 2 7 9 1 6 1 9 4\n",
      " 8 6 1 1 0 2 0 6 5 8 0 0 1 7 8 4 4 9 0 6 8 4 9 2 6 8 0 4 3 5 6 6 4 5 7 9 9\n",
      " 1 3 2 3 6 5 5 0 4 9 4 7 1 4 7 0 4 3 0 7 8 8 1 4 6 9 4 1 9 2 9 9 4 4 1 7 7\n",
      " 1 2 4 3 8 4 9 4 7 6 4 9 8 4 2 9 4 1 1 2 4 4 1 4 7 6 5 4 2 3 7 9 3 4 9 2 8\n",
      " 7 3 9 7 0 1 8 2 4 9 0 9 0 4 2 7 4 4 8 9 8 2 2 9 0 2 3 5 2 0 2 9 3 6 7 7 9\n",
      " 1 7 9 3 0 8 3 1 9 0 0 0 2 4 1 5 5 1 4 8 8 7 7 8 8 8 2 0 4 4 1 3 9 0 7 6 4\n",
      " 2 2 3 0 0 0 9 9 0 3 3 1 1 7 5 2 0 2 9 7 0 3 9 4 7 3 0 2 3 9 0 1 5 5 0 2 1\n",
      " 5 5 2 9 6 5 7 5 7 9 9 7 2 0 8 4 6 8 1 0 0 3 6 7 3 0 4 3 8 1 1 0 3 4 5 3 5\n",
      " 7 2 4 5 2 9 5 2 0 1 7 9 3 7 8 3 5 5 0 1 7 5 6 1 0 9 1 4 2 5 9 2 5 8 9 9 7\n",
      " 3 1 2 9 4 7 6 0 7 4 1 4 4 2 2 2 7 0 0 7 2 9 8 7 0 1 4 0 6 4 1 2 7 5 8 8 7\n",
      " 1 8 7 5 0 5 2 3 7 9 1 3 4 5 8 6 6 7 4 1 4 6 7 8 1 7 8 9 2 0 0 9 1 9 8 9 0\n",
      " 2 3 0 5 6 3 4 4 5 8 7 5 5 7 7 2 2 5 4 8 7 9 2 1 8 9 6 2 7 9 6 7 7 6 6 7 9\n",
      " 1 0 6 9 6 3 7 1 2 3 3 2 5 3 0 8 1 4 7 5 7 9 7 3 1 2 9 9 6 4 0 8 8 7 6 9 9\n",
      " 2 5 7 2 5 0 9 2 4 4 2 5 0 3 1 6 8 1 1 4 2 3 0 1 6 4 1 7 6 0 1 5 8 2 2 1 8\n",
      " 5] [5 3 7 9 7 7 4 3 8 7 7 8 4 6 5 1 2 8 8 1 2 0 3 7 7 6 6 2 0 8 5 0 2 1 9 3 5\n",
      " 2 9 7 4 2 5 8 0 0 2 3 6 7 9 5 5 5 1 1 1 8 9 1 4 4 2 1 8 0 4 9 3 4 4 3 6 6\n",
      " 0 2 6 8 2 9 7 6 1 5 4 1 7 8 2 3 8 1 8 5 5 8 3 9 8 4 1 3 5 1 0 9 0 0 5 5 6\n",
      " 9 5 9 2 7 9 7 3 8 2 6 2 9 8 5 6 4 2 7 9 2 9 1 2 2 4 3 9 8 8 1 0 7 5 5 5 9\n",
      " 7 6 8 2 8 6 0 9 1 7 8 8 0 5 0 9 2 6 0 7 3 8 9 6 0 6 7 6 0 1 5 5 5 3 2 6 3\n",
      " 7 6 3 6 1 1 2 8 1 2 0 0 1 6 5 3 2 7 1 6 6 6 1 5 0 9 7 0 1 0 0 8 3 6 6 5 0\n",
      " 5 8 7 0 7 6 0 9 9 9 4 4 8 7 2 6 3 8 1 7 1 4 1 3 6 1 8 9 1 7 4 7 8 2 2 9 2\n",
      " 7 7 8 5 5 2 4 1 7 0 2 1 0 9 2 9 0 8 1 1 9 0 8 4 5 2 8 3 6 4 8 6 9 2 3 2 0\n",
      " 9 7 2 7 6 8 6 8 0 7 1 0 6 3 2 9 1 2 8 7 9 6 5 7 0 4 8 1 0 3 2 1 1 2 7 7 9\n",
      " 6 4 8 9 4 0 4 9 6 7 4 0 0 7 6 9 0 1 9 8 5 4 2 8 6 0 9 9 7 9 5 1 0 1 0 3 1\n",
      " 6 8 9 8 6 2 7 5 7 3 5 8 3 0 2 7 8 9 1 2 0 5 9 1 6 4 4 5 5 7 1 6 3 7 3 6 9\n",
      " 2 7 3 6 1 2 6 1 5 7 9 5 2 8 9 6 3 2 8 0 0 2 6 4 9 4 6 0 3 6 1 1 4 6 3 1 6\n",
      " 9 1 1 9 7 6 9 7 8 1 6 4 1 1 5 5 9 2 9 2 0 6 6 2 8 0 6 5 8 3 4 9 9 4 6 9 8\n",
      " 1 5 5 9 4 2 9 8 9 9 5 1 7 6 7 7 3 0 1 1 4 4 8 0 5 9 4 2 2 2 7 9 1 6 1 9 4\n",
      " 1 6 1 1 0 2 0 6 5 8 0 0 1 7 5 6 4 9 0 6 8 4 9 2 6 8 0 4 3 0 6 6 9 5 7 9 9\n",
      " 1 5 2 3 6 5 0 0 4 8 4 4 1 4 7 0 4 3 0 7 8 5 1 4 6 9 4 1 9 2 9 9 4 9 9 7 7\n",
      " 9 2 4 3 8 5 7 4 7 6 4 9 8 4 2 7 4 1 1 2 4 5 1 4 7 6 5 9 2 3 7 9 3 4 2 5 5\n",
      " 7 3 9 5 0 1 9 2 4 7 0 9 0 4 7 7 4 6 8 9 8 2 2 9 0 3 3 5 2 0 2 5 3 6 2 7 8\n",
      " 1 7 9 3 0 3 3 1 9 0 0 0 2 4 1 5 5 1 6 8 8 7 7 8 8 8 2 0 4 9 1 3 9 3 7 6 4\n",
      " 2 2 3 6 0 0 9 9 0 3 3 1 3 7 3 2 5 0 9 7 0 3 7 4 7 3 0 6 3 4 0 1 2 5 0 2 1\n",
      " 5 3 2 7 6 5 7 5 1 9 3 7 6 0 8 4 6 8 1 0 0 3 6 7 3 0 4 3 8 1 1 0 3 4 5 2 5\n",
      " 7 8 9 0 2 4 5 2 0 1 7 9 3 7 3 2 5 5 0 1 7 5 6 1 0 2 1 4 2 5 9 2 5 8 9 9 7\n",
      " 3 1 2 9 4 7 6 0 7 4 1 4 4 2 2 2 2 0 0 7 2 9 8 7 0 8 4 0 6 5 9 2 5 5 8 8 9\n",
      " 1 5 7 5 0 5 2 3 7 7 1 3 9 9 0 6 6 7 4 1 4 6 7 8 1 7 8 9 6 0 0 9 1 8 8 9 0\n",
      " 2 3 0 5 6 3 5 4 5 3 7 5 5 7 7 2 2 5 4 8 7 9 2 1 8 9 2 2 7 9 6 7 7 6 6 7 9\n",
      " 1 0 6 9 6 3 7 1 2 3 3 2 5 3 0 8 1 4 7 5 7 9 7 8 1 2 4 9 6 2 0 8 8 7 6 4 9\n",
      " 2 8 7 2 5 2 9 2 4 4 2 8 6 3 1 5 8 1 1 4 0 3 6 1 6 4 1 7 6 0 1 5 8 7 2 1 8\n",
      " 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.824"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_test, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1949068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [9]\n",
      "Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAblElEQVR4nO3df2xV9f3H8dct0CtKe1mt7e2VthZUcAI1Y9B1KF8cFagLipBF1ERYCAwsKtZf6aYic0uVLc64McySDWYi6tgEBDMyqbbErWBAkRBdpU0dONoyWbi3FClIP98/iHdeKeK53Nt3e/t8JCeh995373tnNzy99HLwOeecAADoYWnWCwAA+icCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATAy0XuDLurq6dPDgQWVkZMjn81mvAwDwyDmn9vZ2hUIhpaWd/X1OrwvQwYMHlZ+fb70GAOA8HThwQMOGDTvr/b3uj+AyMjKsVwAAJMC5fj9PWoBWrlypyy67TBdccIFKSkr09ttvf605/tgNAFLDuX4/T0qAXn75ZVVWVmrZsmV65513VFxcrGnTpunQoUPJeDoAQF/kkmDChAmuoqIi+vWpU6dcKBRy1dXV55wNh8NOEgcHBwdHHz/C4fBX/n6f8HdAJ06c0K5du1RWVha9LS0tTWVlZaqvrz/j8Z2dnYpEIjEHACD1JTxAn3zyiU6dOqXc3NyY23Nzc9Xa2nrG46urqxUIBKIHn4ADgP7B/FNwVVVVCofD0ePAgQPWKwEAekDC/x5Qdna2BgwYoLa2tpjb29raFAwGz3i83++X3+9P9BoAgF4u4e+A0tPTNW7cONXU1ERv6+rqUk1NjUpLSxP9dACAPiopV0KorKzU3Llz9e1vf1sTJkzQM888o46ODv3whz9MxtMBAPqgpATo1ltv1X/+8x899thjam1t1TXXXKMtW7ac8cEEAED/5XPOOeslvigSiSgQCFivAQA4T+FwWJmZmWe93/xTcACA/okAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIeIAef/xx+Xy+mGPUqFGJfhoAQB83MBnf9Oqrr9bWrVv/9yQDk/I0AIA+LCllGDhwoILBYDK+NQAgRSTlZ0D79u1TKBTS8OHDdccdd2j//v1nfWxnZ6cikUjMAQBIfQkPUElJidasWaMtW7Zo1apVam5u1nXXXaf29vZuH19dXa1AIBA98vPzE70SAKAX8jnnXDKf4MiRIyosLNTTTz+t+fPnn3F/Z2enOjs7o19HIhEiBAApIBwOKzMz86z3J/3TAUOHDtWVV16pxsbGbu/3+/3y+/3JXgMA0Msk/e8BHT16VE1NTcrLy0v2UwEA+pCEB+iBBx5QXV2dPvroI/3jH//QLbfcogEDBui2225L9FMBAPqwhP8R3Mcff6zbbrtNhw8f1iWXXKJrr71W27dv1yWXXJLopwIA9GFJ/xCCV5FIRIFAwHoN4GsbMGCA55kRI0Z4nonniiKPPPKI5xlJGj9+fFxzXsXz28/vfvc7zzP33nuv5xlJMR+Qgnfn+hAC14IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVKkpGuuuSauuXguWhnPv+B7/fXXe55B/G666aa45l577bUEb9K/cDFSAECvRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMDrRdA/5KW5v2/eVatWuV5Zs6cOZ5nJOmiiy7yPNPR0eF55umnn/Y805P+9re/eZ7Zt2+f55nS0lLPM48++qjnmRtvvNHzjMTVsJONd0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkuRoq4hUIhzzN/+MMfPM/ccMMNnmfee+89zzOS9NBDD3me2bp1a1zPBemjjz7yPBMIBDzPFBcXe56RJJ/P53nGORfXc/VHvAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVLEbf78+Z5n4rmw6Pvvv+955vvf/77nGUlqaWmJaw7xue222zzPLF++3PNMdna25xlJuueeezzPnDx5Mq7n6o94BwQAMEGAAAAmPAdo27ZtmjFjhkKhkHw+nzZs2BBzv3NOjz32mPLy8jR48GCVlZVp3759idoXAJAiPAeoo6NDxcXFWrlyZbf3r1ixQs8++6yee+457dixQxdddJGmTZum48ePn/eyAIDU4flDCOXl5SovL+/2PuecnnnmGT3yyCO6+eabJUnPP/+8cnNztWHDBs2ZM+f8tgUApIyE/gyoublZra2tKisri94WCARUUlKi+vr6bmc6OzsViURiDgBA6ktogFpbWyVJubm5Mbfn5uZG7/uy6upqBQKB6JGfn5/IlQAAvZT5p+CqqqoUDoejx4EDB6xXAgD0gIQGKBgMSpLa2tpibm9ra4ve92V+v1+ZmZkxBwAg9SU0QEVFRQoGg6qpqYneFolEtGPHDpWWlibyqQAAfZznT8EdPXpUjY2N0a+bm5u1e/duZWVlqaCgQEuXLtXPfvYzXXHFFSoqKtKjjz6qUCikmTNnJnJvAEAf5zlAO3fu1PXXXx/9urKyUpI0d+5crVmzRg899JA6Ojq0cOFCHTlyRNdee622bNmiCy64IHFbAwD6PJ9zzlkv8UWRSESBQMB6jX5lwIABcc299dZbnmcmTJjgeeaqq67yPPPhhx96nsH/xPOaeOqppzzPLF261POMz+fzPPPZZ595npGkIUOGeJ7hYqT/Ew6Hv/Ln+uafggMA9E8ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw4fmfY0Dqifdq2PFc2ToeBQUFnme4GvZpoVAorrkHH3zQ88w999wT13P1hCeffDKuOa5snVy8AwIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAxUuizzz6La+7VV1/1PHPTTTd5nvnrX//qeebnP/+55xlJ+uCDD+Ka8yo3N9fzzA9+8APPM/FcyFWShg0bFtecV8eOHfM8c9ddd3me+ctf/uJ5BsnHOyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITPOeesl/iiSCSiQCBgvQa+hsLCQs8zmzZt8jzzzW9+0/OMz+fzPIPz097e7nnm6quv9jzz73//2/MMbITDYWVmZp71ft4BAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBgper0nnnjC80xZWVkSNkmcIUOGeJ6J56Ks8frwww89z0ycONHzzH//+1/PM+g7uBgpAKBXIkAAABOeA7Rt2zbNmDFDoVBIPp9PGzZsiLl/3rx58vl8Mcf06dMTtS8AIEV4DlBHR4eKi4u1cuXKsz5m+vTpamlpiR4vvvjieS0JAEg9A70OlJeXq7y8/Csf4/f7FQwG414KAJD6kvIzoNraWuXk5GjkyJFavHixDh8+fNbHdnZ2KhKJxBwAgNSX8ABNnz5dzz//vGpqavTUU0+prq5O5eXlOnXqVLePr66uViAQiB75+fmJXgkA0At5/iO4c5kzZ07012PGjNHYsWM1YsQI1dbWasqUKWc8vqqqSpWVldGvI5EIEQKAfiDpH8MePny4srOz1djY2O39fr9fmZmZMQcAIPUlPUAff/yxDh8+rLy8vGQ/FQCgD/H8R3BHjx6NeTfT3Nys3bt3KysrS1lZWVq+fLlmz56tYDCopqYmPfTQQ7r88ss1bdq0hC4OAOjbPAdo586duv7666Nff/7zm7lz52rVqlXas2eP/vjHP+rIkSMKhUKaOnWqnnjiCfn9/sRtDQDo87gYKWDgzjvv9DyzevVqzzOdnZ2eZ6TYDxN9Xa+++mpcz4XUxcVIAQC9EgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwk/J/kBvqbSy+91PPM/fffn4RNzrRx48a45riyNXoC74AAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNcjBT4gu9+97ueZ7Zu3ep5xu/3e5557733PM8sWLDA8wzQU3gHBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkwBdMnTrV80w8Fxb95JNPPM/MmjXL88zRo0c9zwA9hXdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJLkaKXi8tzft/J1VWVsb1XD/5yU88z4TDYc8zhYWFnmeOHz/ueQbozXgHBAAwQYAAACY8Bai6ulrjx49XRkaGcnJyNHPmTDU0NMQ85vjx46qoqNDFF1+sIUOGaPbs2Wpra0vo0gCAvs9TgOrq6lRRUaHt27fr9ddf18mTJzV16lR1dHREH3Pfffdp06ZNWrdunerq6nTw4MG4/iEtAEBq8/QhhC1btsR8vWbNGuXk5GjXrl2aNGmSwuGwfv/732vt2rX63ve+J0lavXq1rrrqKm3fvl3f+c53Erc5AKBPO6+fAX3+6Z+srCxJ0q5du3Ty5EmVlZVFHzNq1CgVFBSovr6+2+/R2dmpSCQScwAAUl/cAerq6tLSpUs1ceJEjR49WpLU2tqq9PR0DR06NOaxubm5am1t7fb7VFdXKxAIRI/8/Px4VwIA9CFxB6iiokJ79+7VSy+9dF4LVFVVKRwOR48DBw6c1/cDAPQNcf1F1CVLlmjz5s3atm2bhg0bFr09GAzqxIkTOnLkSMy7oLa2NgWDwW6/l9/vl9/vj2cNAEAf5ukdkHNOS5Ys0fr16/XGG2+oqKgo5v5x48Zp0KBBqqmpid7W0NCg/fv3q7S0NDEbAwBSgqd3QBUVFVq7dq02btyojIyM6M91AoGABg8erEAgoPnz56uyslJZWVnKzMzU3XffrdLSUj4BBwCI4SlAq1atkiRNnjw55vbVq1dr3rx5kqRf/epXSktL0+zZs9XZ2alp06bpt7/9bUKWBQCkDp9zzlkv8UWRSESBQMB6DfQiq1ev9jxz5513xvVchw4d8jxz9913e57585//7HkG6GvC4bAyMzPPej/XggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJuP5FVCBeS5cu9Txz++23J36Rs1i4cKHnmU2bNiVhEyD18Q4IAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBxUgRtx/96EeeZ375y196nvH5fJ5nfvOb33iekaTXXnstrjkA3vEOCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw4XPOOeslvigSiSgQCFiv0a8MHBjfNWn37dvneaagoKBHnueGG27wPCNJBw4ciGsOwJnC4bAyMzPPej/vgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE/FdhRIp5dSpU3HN1dfXe56J52Kks2bN8jzDRUWB3o93QAAAEwQIAGDCU4Cqq6s1fvx4ZWRkKCcnRzNnzlRDQ0PMYyZPniyfzxdzLFq0KKFLAwD6Pk8BqqurU0VFhbZv367XX39dJ0+e1NSpU9XR0RHzuAULFqilpSV6rFixIqFLAwD6Pk8fQtiyZUvM12vWrFFOTo527dqlSZMmRW+/8MILFQwGE7MhACAlndfPgMLhsCQpKysr5vYXXnhB2dnZGj16tKqqqnTs2LGzfo/Ozk5FIpGYAwCQ+uL+GHZXV5eWLl2qiRMnavTo0dHbb7/9dhUWFioUCmnPnj16+OGH1dDQoFdeeaXb71NdXa3ly5fHuwYAoI+KO0AVFRXau3ev3nrrrZjbFy5cGP31mDFjlJeXpylTpqipqUkjRow44/tUVVWpsrIy+nUkElF+fn68awEA+oi4ArRkyRJt3rxZ27Zt07Bhw77ysSUlJZKkxsbGbgPk9/vl9/vjWQMA0Id5CpBzTnfffbfWr1+v2tpaFRUVnXNm9+7dkqS8vLy4FgQApCZPAaqoqNDatWu1ceNGZWRkqLW1VZIUCAQ0ePBgNTU1ae3atbrxxht18cUXa8+ePbrvvvs0adIkjR07Nin/AwAAfZOnAK1atUrS6b9s+kWrV6/WvHnzlJ6erq1bt+qZZ55RR0eH8vPzNXv2bD3yyCMJWxgAkBo8/xHcV8nPz1ddXd15LQQA6B987lxV6WGRSESBQMB6DQDAeQqHw8rMzDzr/VyMFABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABO9LkDOOesVAAAJcK7fz3tdgNrb261XAAAkwLl+P/e5XvaWo6urSwcPHlRGRoZ8Pl/MfZFIRPn5+Tpw4IAyMzONNrTHeTiN83Aa5+E0zsNpveE8OOfU3t6uUCiktLSzv88Z2IM7fS1paWkaNmzYVz4mMzOzX7/APsd5OI3zcBrn4TTOw2nW5yEQCJzzMb3uj+AAAP0DAQIAmOhTAfL7/Vq2bJn8fr/1KqY4D6dxHk7jPJzGeTitL52HXvchBABA/9Cn3gEBAFIHAQIAmCBAAAATBAgAYKLPBGjlypW67LLLdMEFF6ikpERvv/229Uo97vHHH5fP54s5Ro0aZb1W0m3btk0zZsxQKBSSz+fThg0bYu53zumxxx5TXl6eBg8erLKyMu3bt89m2SQ613mYN2/eGa+P6dOn2yybJNXV1Ro/frwyMjKUk5OjmTNnqqGhIeYxx48fV0VFhS6++GINGTJEs2fPVltbm9HGyfF1zsPkyZPPeD0sWrTIaOPu9YkAvfzyy6qsrNSyZcv0zjvvqLi4WNOmTdOhQ4esV+txV199tVpaWqLHW2+9Zb1S0nV0dKi4uFgrV67s9v4VK1bo2Wef1XPPPacdO3booosu0rRp03T8+PEe3jS5znUeJGn69Okxr48XX3yxBzdMvrq6OlVUVGj79u16/fXXdfLkSU2dOlUdHR3Rx9x3333atGmT1q1bp7q6Oh08eFCzZs0y3Drxvs55kKQFCxbEvB5WrFhhtPFZuD5gwoQJrqKiIvr1qVOnXCgUctXV1YZb9bxly5a54uJi6zVMSXLr16+Pft3V1eWCwaD7xS9+Eb3tyJEjzu/3uxdffNFgw57x5fPgnHNz5851N998s8k+Vg4dOuQkubq6Oufc6f/vBw0a5NatWxd9zAcffOAkufr6eqs1k+7L58E55/7v//7P3XvvvXZLfQ29/h3QiRMntGvXLpWVlUVvS0tLU1lZmerr6w03s7Fv3z6FQiENHz5cd9xxh/bv32+9kqnm5ma1trbGvD4CgYBKSkr65eujtrZWOTk5GjlypBYvXqzDhw9br5RU4XBYkpSVlSVJ2rVrl06ePBnzehg1apQKCgpS+vXw5fPwuRdeeEHZ2dkaPXq0qqqqdOzYMYv1zqrXXYz0yz755BOdOnVKubm5Mbfn5ubqn//8p9FWNkpKSrRmzRqNHDlSLS0tWr58ua677jrt3btXGRkZ1uuZaG1tlaRuXx+f39dfTJ8+XbNmzVJRUZGampr04x//WOXl5aqvr9eAAQOs10u4rq4uLV26VBMnTtTo0aMlnX49pKena+jQoTGPTeXXQ3fnQZJuv/12FRYWKhQKac+ePXr44YfV0NCgV155xXDbWL0+QPif8vLy6K/Hjh2rkpISFRYW6k9/+pPmz59vuBl6gzlz5kR/PWbMGI0dO1YjRoxQbW2tpkyZYrhZclRUVGjv3r394uegX+Vs52HhwoXRX48ZM0Z5eXmaMmWKmpqaNGLEiJ5es1u9/o/gsrOzNWDAgDM+xdLW1qZgMGi0Ve8wdOhQXXnllWpsbLRexcznrwFeH2caPny4srOzU/L1sWTJEm3evFlvvvlmzD/fEgwGdeLECR05ciTm8an6ejjbeehOSUmJJPWq10OvD1B6errGjRunmpqa6G1dXV2qqalRaWmp4Wb2jh49qqamJuXl5VmvYqaoqEjBYDDm9RGJRLRjx45+//r4+OOPdfjw4ZR6fTjntGTJEq1fv15vvPGGioqKYu4fN26cBg0aFPN6aGho0P79+1Pq9XCu89Cd3bt3S1Lvej1Yfwri63jppZec3+93a9asce+//75buHChGzp0qGttbbVerUfdf//9rra21jU3N7u///3vrqyszGVnZ7tDhw5Zr5ZU7e3t7t1333Xvvvuuk+Sefvpp9+6777p//etfzjnnnnzySTd06FC3ceNGt2fPHnfzzTe7oqIi9+mnnxpvnlhfdR7a29vdAw884Orr611zc7PbunWr+9a3vuWuuOIKd/z4cevVE2bx4sUuEAi42tpa19LSEj2OHTsWfcyiRYtcQUGBe+ONN9zOnTtdaWmpKy0tNdw68c51HhobG91Pf/pTt3PnTtfc3Ow2btzohg8f7iZNmmS8eaw+ESDnnPv1r3/tCgoKXHp6upswYYLbvn279Uo97tZbb3V5eXkuPT3dXXrppe7WW291jY2N1msl3ZtvvukknXHMnTvXOXf6o9iPPvqoy83NdX6/302ZMsU1NDTYLp0EX3Uejh075qZOneouueQSN2jQIFdYWOgWLFiQcv+R1t3/fklu9erV0cd8+umn7q677nLf+MY33IUXXuhuueUW19LSYrd0EpzrPOzfv99NmjTJZWVlOb/f7y6//HL34IMPunA4bLv4l/DPMQAATPT6nwEBAFITAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDi/wEJ2chYODQZVQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(1, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e029e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
